{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Single Shot MultiBox Detector Self-Driving Cars.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMVjkTWSPMJ7liT/MbScwTT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuyangweng/Project/blob/main/Single_Shot_MultiBox_Detector_Self_Driving_Cars.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIzuSR36LzLz"
      },
      "source": [
        "#https://www.kaggle.com/alincijov/ssd-tf-self-driving-cars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaRNfqFbL--l"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN, CSVLogger\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from math import ceil\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from models.keras_ssd7 import build_model\n",
        "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
        "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
        "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
        "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
        "\n",
        "from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\n",
        "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
        "\n",
        "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
        "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
        "from data_generator.data_augmentation_chain_variable_input_size import DataAugmentationVariableInputSize\n",
        "from data_generator.data_augmentation_chain_constant_input_size import DataAugmentationConstantInputSize\n",
        "from data_generator.data_augmentation_chain_original_ssd import SSDDataAugmentation\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5M3D6UcMS4w"
      },
      "source": [
        "img_height = 300\n",
        "img_width = 480\n",
        "img_channels = 3\n",
        "\n",
        "intensity_mean = 127.5\n",
        "intensity_range = 127.5\n",
        "\n",
        "n_classes = 5\n",
        "scales = [0.08, 0.16, 0.32, 0.64, 0.96]\n",
        "aspect_ratios = [0.5, 1.0, 2.0]\n",
        "two_boxes_for_ar1 = True\n",
        "steps = None\n",
        "offsets = None\n",
        "clip_boxes = False\n",
        "variances = [1.0, 1.0, 1.0, 1.0]\n",
        "normalize_coords = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VS93riWRrY_"
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "model = build_model(image_size=(img_height, img_width, img_channels),\n",
        "                    n_classes=n_classes,\n",
        "                    mode='training',\n",
        "                    l2_regularization=0.0005,\n",
        "                    scales=scales,\n",
        "                    aspect_ratios_global=aspect_ratios,\n",
        "                    aspect_ratios_per_layer=None,\n",
        "                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
        "                    steps=steps,\n",
        "                    offsets=offsets,\n",
        "                    clip_boxes=clip_boxes,\n",
        "                    variances=variances,\n",
        "                    normalize_coords=normalize_coords,\n",
        "                    subtract_mean=intensity_mean,\n",
        "                    divide_by_stddev=intensity_range)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SdpV-uFRvrz"
      },
      "source": [
        "model.load_weights('../input/keras-ssd/ssd7_weights.h5')\n",
        "\n",
        "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
        "\n",
        "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9G0Fp-SRyOa"
      },
      "source": [
        "train_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)\n",
        "val_dataset = DataGenerator(load_images_into_memory=False, hdf5_dataset_path=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR9f97crR1Yt"
      },
      "source": [
        "images_dir = '../input/self-driving-cars/images/'\n",
        "\n",
        "train_labels_filename = '../input/self-driving-cars/labels_train.csv'\n",
        "val_labels_filename   = '../input/self-driving-cars//labels_val.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYi3zlayR4fj"
      },
      "source": [
        "train_dataset.parse_csv(images_dir=images_dir,\n",
        "                        labels_filename=train_labels_filename,\n",
        "                        input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
        "                        include_classes='all')\n",
        "\n",
        "val_dataset.parse_csv(images_dir=images_dir,\n",
        "                      labels_filename=val_labels_filename,\n",
        "                      input_format=['image_name', 'xmin', 'xmax', 'ymin', 'ymax', 'class_id'],\n",
        "                      include_classes='all')\n",
        "\n",
        "train_dataset_size = train_dataset.get_dataset_size()\n",
        "val_dataset_size   = val_dataset.get_dataset_size()\n",
        "\n",
        "print(\"Number of images in the training dataset:\\t{:>6}\".format(train_dataset_size))\n",
        "print(\"Number of images in the validation dataset:\\t{:>6}\".format(val_dataset_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yXYG7UHR_nk"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "data_augmentation_chain = DataAugmentationConstantInputSize(random_brightness=(-48, 48, 0.5),\n",
        "                                                            random_contrast=(0.5, 1.8, 0.5),\n",
        "                                                            random_saturation=(0.5, 1.8, 0.5),\n",
        "                                                            random_hue=(18, 0.5),\n",
        "                                                            random_flip=0.5,\n",
        "                                                            random_translate=((0.03,0.5), (0.03,0.5), 0.5),\n",
        "                                                            random_scale=(0.5, 2.0, 0.5),\n",
        "                                                            n_trials_max=3,\n",
        "                                                            clip_boxes=True,\n",
        "                                                            overlap_criterion='area',\n",
        "                                                            bounds_box_filter=(0.3, 1.0),\n",
        "                                                            bounds_validator=(0.5, 1.0),\n",
        "                                                            n_boxes_min=1,\n",
        "                                                            background=(0,0,0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW33Z4roSC-Y"
      },
      "source": [
        "predictor_sizes = [model.get_layer('classes4').output_shape[1:3],\n",
        "                   model.get_layer('classes5').output_shape[1:3],\n",
        "                   model.get_layer('classes6').output_shape[1:3],\n",
        "                   model.get_layer('classes7').output_shape[1:3]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDHJC83dSFTm"
      },
      "source": [
        "ssd_input_encoder = SSDInputEncoder(img_height=img_height,\n",
        "                                    img_width=img_width,\n",
        "                                    n_classes=n_classes,\n",
        "                                    predictor_sizes=predictor_sizes,\n",
        "                                    scales=scales,\n",
        "                                    aspect_ratios_global=aspect_ratios,\n",
        "                                    two_boxes_for_ar1=two_boxes_for_ar1,\n",
        "                                    steps=steps,\n",
        "                                    offsets=offsets,\n",
        "                                    clip_boxes=clip_boxes,\n",
        "                                    variances=variances,\n",
        "                                    matching_type='multi',\n",
        "                                    pos_iou_threshold=0.5,\n",
        "                                    neg_iou_limit=0.3,\n",
        "                                    normalize_coords=normalize_coords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh9ikppdSJ1H"
      },
      "source": [
        "train_generator = train_dataset.generate(batch_size=batch_size,\n",
        "                                         shuffle=True,\n",
        "                                         transformations=[data_augmentation_chain],\n",
        "                                         label_encoder=ssd_input_encoder,\n",
        "                                         returns={'processed_images',\n",
        "                                                  'encoded_labels'},\n",
        "                                         keep_images_without_gt=False)\n",
        "\n",
        "val_generator = val_dataset.generate(batch_size=batch_size,\n",
        "                                     shuffle=False,\n",
        "                                     transformations=[],\n",
        "                                     label_encoder=ssd_input_encoder,\n",
        "                                     returns={'processed_images',\n",
        "                                              'encoded_labels'},\n",
        "                                     keep_images_without_gt=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY-efKT4SNAl"
      },
      "source": [
        "model_checkpoint = ModelCheckpoint(filepath='ssd7_weights.h5',\n",
        "                                   monitor='val_loss',\n",
        "                                   verbose=1,\n",
        "                                   save_best_only=True,\n",
        "                                   save_weights_only=False,\n",
        "                                   mode='auto',\n",
        "                                   period=1)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               min_delta=0.0,\n",
        "                               patience=10,\n",
        "                               verbose=1)\n",
        "\n",
        "reduce_learning_rate = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                         factor=0.2,\n",
        "                                         patience=8,\n",
        "                                         verbose=1,\n",
        "                                         min_delta=0.001,\n",
        "                                         cooldown=0,\n",
        "                                         min_lr=0.00001)\n",
        "\n",
        "callbacks = [model_checkpoint,\n",
        "             early_stopping,\n",
        "             reduce_learning_rate]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVMgtrmBSSCp"
      },
      "source": [
        "def train(model):\n",
        "    initial_epoch   = 0\n",
        "    final_epoch     = 20\n",
        "    steps_per_epoch = 1000\n",
        "\n",
        "    history = model.fit_generator(generator=train_generator,\n",
        "                                steps_per_epoch=steps_per_epoch,\n",
        "                                epochs=final_epoch,\n",
        "                                callbacks=callbacks,\n",
        "                                validation_data=val_generator,\n",
        "                                validation_steps=ceil(val_dataset_size/batch_size),\n",
        "                                initial_epoch=initial_epoch)\n",
        "\n",
        "    plt.figure(figsize=(20,12))\n",
        "    plt.plot(history.history['loss'], label='loss')\n",
        "    plt.plot(history.history['val_loss'], label='val_loss')\n",
        "    plt.legend(loc='upper right', prop={'size': 24})\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDw2aLL0SWV9"
      },
      "source": [
        "#Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4gaHgpMSVoB"
      },
      "source": [
        "predict_generator = val_dataset.generate(batch_size=1,\n",
        "                                         shuffle=True,\n",
        "                                         transformations=[],\n",
        "                                         label_encoder=None,\n",
        "                                         returns={'processed_images',\n",
        "                                                  'processed_labels',\n",
        "                                                  'filenames'},\n",
        "                                         keep_images_without_gt=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmF4-hwGSa4z"
      },
      "source": [
        "batch_images, batch_labels, batch_filenames = next(predict_generator)\n",
        "\n",
        "i = 0\n",
        "\n",
        "print(\"Image:\", batch_filenames[i])\n",
        "print()\n",
        "print(\"Ground truth boxes:\\n\")\n",
        "print(batch_labels[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNesspjpSdIc"
      },
      "source": [
        "y_pred = model.predict(batch_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2_cRjnwSf0j"
      },
      "source": [
        "# 4: Decode the raw prediction `y_pred`\n",
        "\n",
        "y_pred_decoded = decode_detections(y_pred * 266.,\n",
        "                                   confidence_thresh=0.5,\n",
        "                                   iou_threshold=0.45,\n",
        "                                   top_k=200,\n",
        "                                   normalize_coords=normalize_coords,\n",
        "                                   img_height=img_height,\n",
        "                                   img_width=img_width)\n",
        "\n",
        "np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
        "print(\"Predicted boxes:\\n\")\n",
        "print('   class   conf xmin   ymin   xmax   ymax')\n",
        "print(y_pred_decoded[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PvQnhQ8Sjse"
      },
      "source": [
        "plt.figure(figsize=(20,12))\n",
        "plt.imshow(batch_images[i])\n",
        "\n",
        "current_axis = plt.gca()\n",
        "\n",
        "colors = plt.cm.hsv(np.linspace(0, 1, n_classes+1)).tolist()\n",
        "classes = ['background', 'car', 'truck', 'pedestrian', 'bicyclist', 'light']\n",
        "\n",
        "for box in batch_labels[i]:\n",
        "    xmin = box[1]\n",
        "    ymin = box[2]\n",
        "    xmax = box[3]\n",
        "    ymax = box[4]\n",
        "    label = '{}'.format(classes[int(box[0])])\n",
        "    current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color='green', fill=False, linewidth=2))  \n",
        "    current_axis.text(xmin, ymin, label, size='x-large', color='white', bbox={'facecolor':'green', 'alpha':1.0})\n",
        "\n",
        "for box in y_pred_decoded[i]:\n",
        "    xmin = box[-4]\n",
        "    ymin = box[-3]\n",
        "    xmax = box[-2]\n",
        "    ymax = box[-1]\n",
        "    color = colors[int(box[0])]\n",
        "    label = '{}: {:.2f}'.format(classes[int(box[0])], box[1])\n",
        "    current_axis.add_patch(plt.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, color=color, fill=False, linewidth=2))  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}